# LLM Training with TPU and SPMD Sharding

This repository contains a Jupyter Notebook designed for training large language models (LLMs) using TPU resources and PyTorch SPMD sharding. The notebook has been tested successfully on a 7B model using Kaggle TPU. The notebook was used for training Llama 3.2 3B on medical corpus text data.

## Supported Model Families
This notebook supports the following model architectures:
- GPT-NeoX
- T5
- LLaMA
- CLIP
- LLaVA
- Gemma
- GPT-2
- Qwen
- Mixtral
- Phi
